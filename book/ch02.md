---
title: Chapter 2 — Methodology: Letting the Data Speak
---

```{note}
This chapter is a lightly adapted copy of `chapter_02_draft.md` for Jupyter Book.
```

# Chapter 2: Methodology—Letting the Data Speak

## The Problem with Human Interpretation

In 2019, a debate erupted online after a journalist compared rhetoric from conservative commentators to language found in a mass shooter's manifesto. Conservatives accused the journalist of guilt-by-association and cherry-picking quotes. Progressives accused conservatives of refusing to acknowledge obvious patterns. Both sides selected their preferred evidence, questioned the other's motives, and talked past each other completely.

This is what happens when we rely on human interpretation alone for politically charged textual analysis. We see what we expect to see. We find what we're looking for. And everyone else accuses us of bias—often correctly.

The analysis in this book faces the same problem, but multiplied. We're comparing Jordan Peterson—a figure who inspires fierce loyalty and equally fierce opposition—to Anders Breivik, a mass murderer. Any claim about overlap will be read through ideological lenses. Peterson's defenders will assume we're trying to smear him. His critics will assume we're understating the connection. No matter what we say, someone will accuse us of agenda-driven interpretation.

So we need a different approach. One that doesn't depend on which quotes we select, which similarities we highlight, or which differences we emphasize. We need methods that are transparent, replicable, and—to the extent possible—objective.

That's where computational text analysis comes in.

## What Computational Analysis Can (and Can't) Do

Natural Language Processing (NLP) techniques measure textual patterns using mathematical operations on word frequencies, distributions, and co-occurrences. These methods don't read for meaning in the way humans do. They count, weight, cluster, and calculate. The results are numbers: similarity scores, frequency distributions, statistical patterns.

This has enormous advantages for controversial topics:

**Transparency**: Every calculation can be shown. The code is provided. Anyone can verify the results.

**Replicability**: Run the same analysis on the same texts, you get the same numbers. Always.

**Systematic coverage**: The algorithms examine every word, every phrase, every pattern—not just the ones that fit a narrative.

**Objectivity**: TF-IDF vectorization doesn't know who Jordan Peterson is. It doesn't care about the Norway attacks. It just measures word distributions.

But computational analysis also has critical limitations:

**It can't determine causation**: A 16% semantic similarity tells us nothing about whether Peterson influenced Breivik, or whether both drew from a common source, or whether the overlap is meaningful at all.

**It can't assess intent**: Algorithms can't tell you whether Peterson deliberately avoided certain terminology, or whether Breivik consciously drew on mainstream conservative discourse.

**It can't make moral judgments**: The fact that two texts share vocabulary doesn't tell us if they're morally equivalent, or who bears responsibility, or what should be done about it.

**It requires human interpretation**: Someone has to decide which texts to analyze, which methods to use, and what the numbers mean. Those choices matter.

This chapter explains the methods we used, why we chose them, what their limitations are, and what interpretive choices we made along the way. The goal is not to hide behind mathematics but to show exactly how we arrived at our findings so readers can evaluate them critically.
